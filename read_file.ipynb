{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "# try:\n",
    "#   import open3d as o3d\n",
    "# except:\n",
    "#   subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"open3d\"])\n",
    "#   import open3d as o3d\n",
    "import open3d as o3d\n",
    "from config import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Read Points Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read ply file\n",
    "# path = img_dir + \"/1.ply\"\n",
    "path = \"1.ply\"\n",
    "pcd = o3d.io.read_point_cloud(path)\n",
    "# ply_file.paint_uniform_color([1, 0.706, 0])\n",
    "\n",
    "# visualize ply file\n",
    "o3d.visualization.draw_geometries([pcd])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.97852   1.19141  -2.0918  ]\n",
      " [-1.96973   1.19141  -2.0918  ]\n",
      " [-1.97461   1.20117  -2.10742 ]\n",
      " ...\n",
      " [ 0.442383 -0.252197 -0.442627]\n",
      " [ 0.44458  -0.252197 -0.442627]\n",
      " [ 0.446533 -0.252197 -0.442627]]\n",
      "----------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([False, False, False, ...,  True,  True,  True])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_xyz = np.asarray(pcd.points)\n",
    "print(n_xyz)\n",
    "print(\"----------------------------\")\n",
    "n_xyz[:, 0] > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Crop Img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#crop data\n",
    "def crop(pcd, range_x, range_y, range_z):\n",
    "  n_xyz = np.asarray(pcd.points)\n",
    "  mask_x = (n_xyz[:, 0] > range_x[0]) & (n_xyz[:, 0] < range_x[1])\n",
    "  \n",
    "  # print(mask_x)\n",
    "  mask_y = (n_xyz[:, 1] > range_y[0]) & (n_xyz[:, 1] < range_y[1])\n",
    "  mask_z = (n_xyz[:, 2] > range_z[0]) & (n_xyz[:, 2] < range_z[1])\n",
    "  mask = mask_x & mask_y & mask_z\n",
    "  # print(mask)\n",
    "  cropPCD = o3d.geometry.PointCloud()\n",
    "  cropPCD.points = o3d.utility.Vector3dVector(n_xyz[mask])\n",
    "  return cropPCD\n",
    "\n",
    "newPCD = crop(pcd, [-0.5,0.5], [-0.5,0.5], [-1.25,0])\n",
    "# o3d.visualization.draw_geometries([newPCD])\n",
    "# crop2(pcd, min_x, min_y, min_z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. DownSampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#down sample\n",
    "downPCD = newPCD.voxel_down_sample(voxel_size = 0.01  )\n",
    "# downPCD = voxel_down_sample(newPCD, voxel_size = 0.01) => error\n",
    "\n",
    "#rotate img\n",
    "# R = downPCD.get_rotation_matrix_from_xyz((0.7 * np.pi, 0, 0.6 * np.pi))\n",
    "# downPCD = downPCD.rotate(R, center=(0,0,0))\n",
    "# o3d.visualization.draw_geometries([downPCD])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Plane segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plane equation: -0.08x + 0.84y + 0.54z + 0.48 = 0\n",
      "Number of points in the plane: 6091\n",
      "Number of points in the plane: 1997\n",
      "Processing with the 1 loop\n",
      "Number of points in the plane: 1143\n",
      "Number of points in the other: 854\n"
     ]
    }
   ],
   "source": [
    "# Plane segmentation\n",
    "def plane(pcd):\n",
    "    plane_model, inliers = pcd.segment_plane(distance_threshold=0.01,\n",
    "                                         ransac_n=3,\n",
    "                                         num_iterations=1000)\n",
    "    [a, b, c, d] = plane_model\n",
    "    print(f\"Plane equation: {a:.2f}x + {b:.2f}y + {c:.2f}z + {d:.2f} = 0\")\n",
    "\n",
    "    plane = pcd.select_by_index(inliers)\n",
    "    # Count points in plane\n",
    "    points_plane = np.asarray(plane.points)\n",
    "    print(f\"Number of points in the plane: {points_plane.shape[0]}\")\n",
    "\n",
    "    # inlier_cloud.paint_uniform_color([1.0, 0, 0])\n",
    "    other = pcd.select_by_index(inliers, invert=True)\n",
    "    points_others = np.asarray(other.points)\n",
    "    print(f\"Number of points in the plane: {points_others.shape[0]}\")\n",
    "\n",
    "    # Processing with loop\n",
    "    i = 1\n",
    "    while points_others.shape[0] > 0:\n",
    "        print(\"Processing with the {} loop\".format(i))\n",
    "        i += 1\n",
    "        print(\"Total surfaces:\", i)\n",
    "        # Segment plane\n",
    "        plane_model, inliers = other.segment_plane(distance_threshold=0.01,\n",
    "                                                    ransac_n=3,\n",
    "                                                    num_iterations=1000)\n",
    "        # Extract inliers and outliers\n",
    "        plane = other.select_by_index(inliers)\n",
    "        other = other.select_by_index(inliers, invert=True)\n",
    "        # Count points in plane\n",
    "        points_plane = np.asarray(plane.points)\n",
    "        print(f\"Number of points in the plane: {points_plane.shape[0]}\")\n",
    "        # Count points in other\n",
    "        points_others = np.asarray(other.points)\n",
    "        print(f\"Number of points in the other: {points_others.shape[0]}\")\n",
    "        # Visualize\n",
    "        o3d.visualization.draw_geometries([plane])\n",
    "        # Break if no points left\n",
    "        if points_others.shape[0] == 0:\n",
    "            break\n",
    "        # Update\n",
    "        plane = other\n",
    "        # other = other.select_by_index(inliers, invert=True)\n",
    "        return plane\n",
    "\n",
    "\n",
    "    # return plane, points_plane, other, points_others\n",
    "plane = plane(downPCD)\n",
    "\n",
    "# place_plane, count_points_1, other, points_others = plane(downPCD)\n",
    "# o3d.visualization.draw_geometries([other])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Count the number of points in each plane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found device that supports advanced mode: Intel RealSense D435\n",
      "Advanced mode is enabled\n",
      "Depth Control: \n",
      " minusDecrement: 10, deepSeaMedianThreshold: 500, scoreThreshA: 511, scoreThreshB: 2047, textureDifferenceThreshold: 0, textureCountThreshold: 0, deepSeaSecondPeakThreshold: 325, deepSeaNeighborThreshold: 7, lrAgreeThreshold: 24\n",
      "RSM: \n",
      " rsmBypass: 0, diffThresh: 4, sloRauDiffThresh: 1, removeThresh: 63\n",
      "RAU Support Vector Control: \n",
      " minWest: 1, minEast: 1, minWEsum: 3, minNorth: 1, minSouth: 1, minNSsum: 3, uShrink: 3, vShrink: 1\n",
      "Color Control: \n",
      " disableSADColor: 0, disableRAUColor: 0, disableSLORightColor: 0, disableSLOLeftColor: 0, disableSADNormalize: 0\n",
      "RAU Thresholds Control: \n",
      " rauDiffThresholdRed: 51, rauDiffThresholdGreen: 51, rauDiffThresholdBlue: 51\n",
      "SLO Color Thresholds Control: \n",
      " diffThresholdRed: 72, diffThresholdGreen: 72, diffThresholdBlue: 72\n",
      "SLO Penalty Control: \n",
      " sloK1Penalty: 60, sloK2Penalty: 342, sloK1PenaltyMod1: 105, sloK2PenaltyMod1: 190, sloK1PenaltyMod2: 70, sloK2PenaltyMod2: 130\n",
      "HDAD: \n",
      " lambdaCensus: 26, lambdaAD: 800, ignoreSAD: 0\n",
      "Color Correction: \n",
      " colorCorrection1: 0.298828, colorCorrection2: 0.293945, colorCorrection3: 0.293945, colorCorrection4: 0.114258, colorCorrection5: -0, colorCorrection6: -0, colorCorrection7: -0, colorCorrection8: -0, colorCorrection9: -0, colorCorrection10: -0, colorCorrection11: -0, colorCorrection12: -0\n",
      "Depth Table: \n",
      " depthUnits: 1000, depthClampMin: 0, depthClampMax: 65536, disparityMode: 0, disparityShift: 0\n",
      "Auto Exposure Control: \n",
      " Mean Intensity Set Point: 1536\n",
      "Census: \n",
      " uDiameter: 9, vDiameter: 9\n",
      "Depth Control Min Values: \n",
      "  minusDecrement: 0, deepSeaMedianThreshold: 0, scoreThreshA: 0, scoreThreshB: 0, textureDifferenceThreshold: 0, textureCountThreshold: 0, deepSeaSecondPeakThreshold: 0, deepSeaNeighborThreshold: 0, lrAgreeThreshold: 0\n",
      "Depth Control Max Values: \n",
      "  minusDecrement: 255, deepSeaMedianThreshold: 1023, scoreThreshA: 1023, scoreThreshB: 4095, textureDifferenceThreshold: 4095, textureCountThreshold: 1023, deepSeaSecondPeakThreshold: 1023, deepSeaNeighborThreshold: 1023, lrAgreeThreshold: 2047\n",
      "After Setting new value, Depth Control: \n",
      " minusDecrement: 10, deepSeaMedianThreshold: 500, scoreThreshA: 511, scoreThreshB: 2047, textureDifferenceThreshold: 0, textureCountThreshold: 0, deepSeaSecondPeakThreshold: 325, deepSeaNeighborThreshold: 7, lrAgreeThreshold: 24\n",
      "Controls as JSON: \n",
      " {\n",
      "    \"device\": {\n",
      "        \"fw version\": \"05.13.00.50\",\n",
      "        \"name\": \"Intel RealSense D435\",\n",
      "        \"product line\": \"D400\"\n",
      "    },\n",
      "    \"parameters\": {\n",
      "        \"aux-param-autoexposure-setpoint\": \"1536\",\n",
      "        \"aux-param-colorcorrection1\": \"0.298828\",\n",
      "        \"aux-param-colorcorrection10\": \"-0\",\n",
      "        \"aux-param-colorcorrection11\": \"-0\",\n",
      "        \"aux-param-colorcorrection12\": \"-0\",\n",
      "        \"aux-param-colorcorrection2\": \"0.293945\",\n",
      "        \"aux-param-colorcorrection3\": \"0.293945\",\n",
      "        \"aux-param-colorcorrection4\": \"0.114258\",\n",
      "        \"aux-param-colorcorrection5\": \"-0\",\n",
      "        \"aux-param-colorcorrection6\": \"-0\",\n",
      "        \"aux-param-colorcorrection7\": \"-0\",\n",
      "        \"aux-param-colorcorrection8\": \"-0\",\n",
      "        \"aux-param-colorcorrection9\": \"-0\",\n",
      "        \"aux-param-depthclampmax\": \"65536\",\n",
      "        \"aux-param-depthclampmin\": \"0\",\n",
      "        \"aux-param-disparityshift\": \"0\",\n",
      "        \"controls-autoexposure-auto\": \"True\",\n",
      "        \"controls-autoexposure-manual\": \"8500\",\n",
      "        \"controls-color-autoexposure-auto\": \"True\",\n",
      "        \"controls-color-autoexposure-manual\": \"166\",\n",
      "        \"controls-color-backlight-compensation\": \"0\",\n",
      "        \"controls-color-brightness\": \"0\",\n",
      "        \"controls-color-contrast\": \"50\",\n",
      "        \"controls-color-gain\": \"64\",\n",
      "        \"controls-color-gamma\": \"300\",\n",
      "        \"controls-color-hue\": \"0\",\n",
      "        \"controls-color-power-line-frequency\": \"3\",\n",
      "        \"controls-color-saturation\": \"64\",\n",
      "        \"controls-color-sharpness\": \"50\",\n",
      "        \"controls-color-white-balance-auto\": \"True\",\n",
      "        \"controls-color-white-balance-manual\": \"4600\",\n",
      "        \"controls-depth-gain\": \"16\",\n",
      "        \"controls-laserpower\": \"150\",\n",
      "        \"controls-laserstate\": \"on\",\n",
      "        \"ignoreSAD\": \"0\",\n",
      "        \"param-amplitude-factor\": \"0\",\n",
      "        \"param-autoexposure-setpoint\": \"1536\",\n",
      "        \"param-censusenablereg-udiameter\": \"9\",\n",
      "        \"param-censusenablereg-vdiameter\": \"9\",\n",
      "        \"param-censususize\": \"9\",\n",
      "        \"param-censusvsize\": \"9\",\n",
      "        \"param-depthclampmax\": \"65536\",\n",
      "        \"param-depthclampmin\": \"0\",\n",
      "        \"param-depthunits\": \"1000\",\n",
      "        \"param-disableraucolor\": \"0\",\n",
      "        \"param-disablesadcolor\": \"0\",\n",
      "        \"param-disablesadnormalize\": \"0\",\n",
      "        \"param-disablesloleftcolor\": \"0\",\n",
      "        \"param-disableslorightcolor\": \"0\",\n",
      "        \"param-disparitymode\": \"0\",\n",
      "        \"param-disparityshift\": \"0\",\n",
      "        \"param-lambdaad\": \"800\",\n",
      "        \"param-lambdacensus\": \"26\",\n",
      "        \"param-leftrightthreshold\": \"24\",\n",
      "        \"param-maxscorethreshb\": \"2047\",\n",
      "        \"param-medianthreshold\": \"500\",\n",
      "        \"param-minscorethresha\": \"511\",\n",
      "        \"param-neighborthresh\": \"7\",\n",
      "        \"param-raumine\": \"1\",\n",
      "        \"param-rauminn\": \"1\",\n",
      "        \"param-rauminnssum\": \"3\",\n",
      "        \"param-raumins\": \"1\",\n",
      "        \"param-rauminw\": \"1\",\n",
      "        \"param-rauminwesum\": \"3\",\n",
      "        \"param-regioncolorthresholdb\": \"0.0499022\",\n",
      "        \"param-regioncolorthresholdg\": \"0.0499022\",\n",
      "        \"param-regioncolorthresholdr\": \"0.0499022\",\n",
      "        \"param-regionshrinku\": \"3\",\n",
      "        \"param-regionshrinkv\": \"1\",\n",
      "        \"param-robbinsmonrodecrement\": \"10\",\n",
      "        \"param-robbinsmonroincrement\": \"10\",\n",
      "        \"param-rsmdiffthreshold\": \"4\",\n",
      "        \"param-rsmrauslodiffthreshold\": \"1\",\n",
      "        \"param-rsmremovethreshold\": \"0.375\",\n",
      "        \"param-scanlineedgetaub\": \"72\",\n",
      "        \"param-scanlineedgetaug\": \"72\",\n",
      "        \"param-scanlineedgetaur\": \"72\",\n",
      "        \"param-scanlinep1\": \"60\",\n",
      "        \"param-scanlinep1onediscon\": \"105\",\n",
      "        \"param-scanlinep1twodiscon\": \"70\",\n",
      "        \"param-scanlinep2\": \"342\",\n",
      "        \"param-scanlinep2onediscon\": \"190\",\n",
      "        \"param-scanlinep2twodiscon\": \"130\",\n",
      "        \"param-secondpeakdelta\": \"325\",\n",
      "        \"param-texturecountthresh\": \"0\",\n",
      "        \"param-texturedifferencethresh\": \"0\",\n",
      "        \"param-usersm\": \"1\",\n",
      "        \"param-zunits\": \"1000\"\n",
      "    },\n",
      "    \"schema version\": 1\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## License: Apache 2.0. See LICENSE file in root directory.\n",
    "## Copyright(c) 2017 Intel Corporation. All Rights Reserved.\n",
    "\n",
    "#####################################################\n",
    "##          rs400 advanced mode tutorial           ##\n",
    "#####################################################\n",
    "\n",
    "# First import the library\n",
    "import pyrealsense2 as rs\n",
    "import time\n",
    "import json\n",
    "\n",
    "DS5_product_ids = [\"0AD1\", \"0AD2\", \"0AD3\", \"0AD4\", \"0AD5\", \"0AF6\", \"0AFE\", \"0AFF\", \"0B00\", \"0B01\", \"0B03\", \"0B07\", \"0B3A\", \"0B5C\"]\n",
    "\n",
    "def find_device_that_supports_advanced_mode() :\n",
    "    ctx = rs.context()\n",
    "    ds5_dev = rs.device()\n",
    "    devices = ctx.query_devices();\n",
    "    for dev in devices:\n",
    "        if dev.supports(rs.camera_info.product_id) and str(dev.get_info(rs.camera_info.product_id)) in DS5_product_ids:\n",
    "            if dev.supports(rs.camera_info.name):\n",
    "                print(\"Found device that supports advanced mode:\", dev.get_info(rs.camera_info.name))\n",
    "            return dev\n",
    "    raise Exception(\"No D400 product line device that supports advanced mode was found\")\n",
    "\n",
    "try:\n",
    "    dev = find_device_that_supports_advanced_mode()\n",
    "    advnc_mode = rs.rs400_advanced_mode(dev)\n",
    "    print(\"Advanced mode is\", \"enabled\" if advnc_mode.is_enabled() else \"disabled\")\n",
    "\n",
    "    # Loop until we successfully enable advanced mode\n",
    "    while not advnc_mode.is_enabled():\n",
    "        print(\"Trying to enable advanced mode...\")\n",
    "        advnc_mode.toggle_advanced_mode(True)\n",
    "        # At this point the device will disconnect and re-connect.\n",
    "        print(\"Sleeping for 5 seconds...\")\n",
    "        time.sleep(5)\n",
    "        # The 'dev' object will become invalid and we need to initialize it again\n",
    "        dev = find_device_that_supports_advanced_mode()\n",
    "        advnc_mode = rs.rs400_advanced_mode(dev)\n",
    "        print(\"Advanced mode is\", \"enabled\" if advnc_mode.is_enabled() else \"disabled\")\n",
    "\n",
    "    # Get each control's current value\n",
    "    print(\"Depth Control: \\n\", advnc_mode.get_depth_control())\n",
    "    print(\"RSM: \\n\", advnc_mode.get_rsm())\n",
    "    print(\"RAU Support Vector Control: \\n\", advnc_mode.get_rau_support_vector_control())\n",
    "    print(\"Color Control: \\n\", advnc_mode.get_color_control())\n",
    "    print(\"RAU Thresholds Control: \\n\", advnc_mode.get_rau_thresholds_control())\n",
    "    print(\"SLO Color Thresholds Control: \\n\", advnc_mode.get_slo_color_thresholds_control())\n",
    "    print(\"SLO Penalty Control: \\n\", advnc_mode.get_slo_penalty_control())\n",
    "    print(\"HDAD: \\n\", advnc_mode.get_hdad())\n",
    "    print(\"Color Correction: \\n\", advnc_mode.get_color_correction())\n",
    "    print(\"Depth Table: \\n\", advnc_mode.get_depth_table())\n",
    "    print(\"Auto Exposure Control: \\n\", advnc_mode.get_ae_control())\n",
    "    print(\"Census: \\n\", advnc_mode.get_census())\n",
    "\n",
    "    #To get the minimum and maximum value of each control use the mode value:\n",
    "    query_min_values_mode = 1\n",
    "    query_max_values_mode = 2\n",
    "    current_std_depth_control_group = advnc_mode.get_depth_control()\n",
    "    min_std_depth_control_group = advnc_mode.get_depth_control(query_min_values_mode)\n",
    "    max_std_depth_control_group = advnc_mode.get_depth_control(query_max_values_mode)\n",
    "    print(\"Depth Control Min Values: \\n \", min_std_depth_control_group)\n",
    "    print(\"Depth Control Max Values: \\n \", max_std_depth_control_group)\n",
    "\n",
    "    # Set some control with a new (median) value\n",
    "    current_std_depth_control_group.scoreThreshA = int((max_std_depth_control_group.scoreThreshA - min_std_depth_control_group.scoreThreshA) / 2)\n",
    "    advnc_mode.set_depth_control(current_std_depth_control_group)\n",
    "    print(\"After Setting new value, Depth Control: \\n\", advnc_mode.get_depth_control())\n",
    "\n",
    "    # Serialize all controls to a Json string\n",
    "    serialized_string = advnc_mode.serialize_json()\n",
    "    print(\"Controls as JSON: \\n\", serialized_string)\n",
    "    as_json_object = json.loads(serialized_string)\n",
    "\n",
    "    # We can also load controls from a json string\n",
    "    # For Python 2, the values in 'as_json_object' dict need to be converted from unicode object to utf-8\n",
    "    if type(next(iter(as_json_object))) != str:\n",
    "        as_json_object = {k.encode('utf-8'): v.encode(\"utf-8\") for k, v in as_json_object.items()}\n",
    "    # The C++ JSON parser requires double-quotes for the json object so we need\n",
    "    # to replace the single quote of the pythonic json to double-quotes\n",
    "    json_string = str(as_json_object).replace(\"'\", '\\\"')\n",
    "    advnc_mode.load_json(json_string)\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    pass\n",
    "1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "## License: Apache 2.0. See LICENSE file in root directory.\n",
    "## Copyright(c) 2015-2017 Intel Corporation. All Rights Reserved.\n",
    "\n",
    "###############################################\n",
    "##      Open CV and Numpy integration        ##\n",
    "###############################################\n",
    "\n",
    "import pyrealsense2 as rs\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "from config import *\n",
    "\n",
    "# Create Trackbar for Threshold\n",
    "# cv2.namedWindow('Depth Image')\n",
    "cv2.namedWindow('RealSense', cv2.WINDOW_AUTOSIZE)\n",
    "cv2.createTrackbar('FPS', 'RealSense', 0, 50, lambda x: x+1)\n",
    "\n",
    "# Configure depth and color streams\n",
    "pipeline = rs.pipeline()\n",
    "config = rs.config()\n",
    "\n",
    "# Get device product line for setting a supporting resolution\n",
    "pipeline_wrapper = rs.pipeline_wrapper(pipeline)\n",
    "pipeline_profile = config.resolve(pipeline_wrapper)\n",
    "device = pipeline_profile.get_device()\n",
    "device_product_line = str(device.get_info(rs.camera_info.product_line))\n",
    "\n",
    "found_rgb = False\n",
    "for s in device.sensors:\n",
    "    if s.get_info(rs.camera_info.name) == 'RGB Camera':\n",
    "        found_rgb = True\n",
    "        break\n",
    "if not found_rgb:\n",
    "    print(\"The demo requires Depth camera with Color sensor\")\n",
    "    exit(0)\n",
    "\n",
    "fps = cv2.getTrackbarPos('FPS', 'RealSense')\n",
    "print(fps)\n",
    "config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, fps)\n",
    "\n",
    "if device_product_line == 'L500':\n",
    "    config.enable_stream(rs.stream.color, 960, 540, rs.format.bgr8, fps)\n",
    "else:\n",
    "    config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, fps)\n",
    "\n",
    "# Start streaming\n",
    "pipeline.start(config)\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        # print(pipeline)\n",
    "        # Wait for a coherent pair of frames: depth and color\n",
    "        frames = pipeline.wait_for_frames()\n",
    "        depth_frame = frames.get_depth_frame()\n",
    "        color_frame = frames.get_color_frame()\n",
    "        if not depth_frame or not color_frame:\n",
    "            continue\n",
    "        \n",
    "        # Convert images to numpy arrays\n",
    "        depth_image = np.asanyarray(depth_frame.get_data())\n",
    "        color_image = np.asanyarray(color_frame.get_data())\n",
    "\n",
    "        # Apply colormap on depth image (image must be converted to 8-bit per pixel first)\n",
    "        depth_colormap = cv2.applyColorMap(cv2.convertScaleAbs(depth_image, alpha=0.03), cv2.COLORMAP_JET)\n",
    "\n",
    "        depth_colormap_dim = depth_colormap.shape\n",
    "        color_colormap_dim = color_image.shape\n",
    "\n",
    "        # If depth and color resolutions are different, resize color image to match depth image for display\n",
    "        if depth_colormap_dim != color_colormap_dim:\n",
    "            resized_color_image = cv2.resize(color_image, dsize=(depth_colormap_dim[1], depth_colormap_dim[0]), interpolation=cv2.INTER_AREA)\n",
    "            images = np.hstack((resized_color_image, depth_colormap))\n",
    "        else:\n",
    "            images = np.hstack((color_image, depth_colormap))\n",
    "        \n",
    "        # Flip camera image\n",
    "        images = cv2.flip(images, 1)\n",
    "\n",
    "        # Save images\n",
    "        import os\n",
    "        # Create directory if not exist\n",
    "        if not os.path.exists('images'):\n",
    "            os.mkdir('images')\n",
    "        \n",
    "        if count // 2 == 0:\n",
    "            if len(os.listdir(\"./images\"))!=10:\n",
    "                cv2.imwrite(\"./images/image_\" + str(count) + \".png\", images)    \n",
    "        count += 1\n",
    "\n",
    "        # Show images\n",
    "        cv2.namedWindow('RealSense', cv2.WINDOW_AUTOSIZE)\n",
    "        cv2.imshow('RealSense', images)\n",
    "        key = cv2.waitKey(1)\n",
    "        # Press esc or 'q' to close the image window\n",
    "        if key & 0xFF == ord('q') or key == 27:\n",
    "            cv2.destroyAllWindows()\n",
    "            break\n",
    "        \n",
    "finally:\n",
    "\n",
    "    # Stop streaming\n",
    "    pipeline.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Failed to open scan_element /sys/devices/pci0000:00/0000:00:14.0/usb2/2-4/2-4:1.5/0003:8086:0B5C.0005/HID-SENSOR-200073.3.auto/iio:device1/scan_elements/in_accel_y_en Last Error: Permission denied",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/thanhnd86/python/GraduationProject/read_file.ipynb Cell 15'\u001b[0m in \u001b[0;36m<cell line: 29>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/thanhnd86/python/GraduationProject/read_file.ipynb#ch0000017?line=25'>26</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpose_data\u001b[39m(pose):\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/thanhnd86/python/GraduationProject/read_file.ipynb#ch0000017?line=26'>27</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39masarray([pose\u001b[39m.\u001b[39mtx, pose\u001b[39m.\u001b[39mty, pose\u001b[39m.\u001b[39mtz, pose\u001b[39m.\u001b[39mqx, pose\u001b[39m.\u001b[39mqy, pose\u001b[39m.\u001b[39mqz, pose\u001b[39m.\u001b[39mqw])\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/thanhnd86/python/GraduationProject/read_file.ipynb#ch0000017?line=28'>29</a>\u001b[0m p \u001b[39m=\u001b[39m initialize_camera()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/thanhnd86/python/GraduationProject/read_file.ipynb#ch0000017?line=29'>30</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/thanhnd86/python/GraduationProject/read_file.ipynb#ch0000017?line=30'>31</a>\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n",
      "\u001b[1;32m/home/thanhnd86/python/GraduationProject/read_file.ipynb Cell 15'\u001b[0m in \u001b[0;36minitialize_camera\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/thanhnd86/python/GraduationProject/read_file.ipynb#ch0000017?line=11'>12</a>\u001b[0m conf\u001b[39m.\u001b[39menable_stream(rs\u001b[39m.\u001b[39mstream\u001b[39m.\u001b[39mgyro)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/thanhnd86/python/GraduationProject/read_file.ipynb#ch0000017?line=12'>13</a>\u001b[0m \u001b[39m# conf.enable_stream(rs.stream.pose)\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/thanhnd86/python/GraduationProject/read_file.ipynb#ch0000017?line=13'>14</a>\u001b[0m prof \u001b[39m=\u001b[39m p\u001b[39m.\u001b[39;49mstart(conf)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/thanhnd86/python/GraduationProject/read_file.ipynb#ch0000017?line=14'>15</a>\u001b[0m \u001b[39mreturn\u001b[39;00m prof\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to open scan_element /sys/devices/pci0000:00/0000:00:14.0/usb2/2-4/2-4:1.5/0003:8086:0B5C.0005/HID-SENSOR-200073.3.auto/iio:device1/scan_elements/in_accel_y_en Last Error: Permission denied"
     ]
    }
   ],
   "source": [
    "import pyrealsense2 as rs\n",
    "import numpy as np\n",
    "\n",
    "fps = 30\n",
    "\n",
    "def initialize_camera():\n",
    "    # start the frames pipe\n",
    "    p = rs.pipeline()\n",
    "    conf = rs.config()\n",
    "    # conf.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, fps)\n",
    "    conf.enable_stream(rs.stream.accel)\n",
    "    conf.enable_stream(rs.stream.gyro)\n",
    "    # conf.enable_stream(rs.stream.pose)\n",
    "    prof = p.start(conf)\n",
    "    return prof #????\n",
    "\n",
    "\n",
    "def gyro_data(gyro):\n",
    "    return np.asarray([gyro.x, gyro.y, gyro.z])\n",
    "\n",
    "\n",
    "def accel_data(accel):\n",
    "    return np.asarray([accel.x, accel.y, accel.z])\n",
    "\n",
    "\n",
    "def pose_data(pose):\n",
    "    return np.asarray([pose.tx, pose.ty, pose.tz, pose.qx, pose.qy, pose.qz, pose.qw])\n",
    "\n",
    "p = initialize_camera()\n",
    "try:\n",
    "    while True:\n",
    "        f = p.wait_for_frames()\n",
    "        accel = accel_data(f[0].as_motion_frame().get_motion_data())\n",
    "        gyro = gyro_data(f[1].as_motion_frame().get_motion_data())\n",
    "        # pose = pose_data(f[2].as_pose_frame().get_pose_data())\n",
    "        print(\"accelerometer: \", accel)\n",
    "        print(\"gyro: \", gyro)\n",
    "\n",
    "finally:\n",
    "    p.stop()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
