{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "# try:\n",
    "#   import open3d as o3d\n",
    "# except:\n",
    "#   subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"open3d\"])\n",
    "#   import open3d as o3d\n",
    "import open3d as o3d\n",
    "from config import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Read Points Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read ply file\n",
    "path = img_dir + \"/1.ply\"\n",
    "pcd = o3d.io.read_point_cloud(path)\n",
    "# ply_file.paint_uniform_color([1, 0.706, 0])\n",
    "\n",
    "# visualize ply file\n",
    "# o3d.visualization.draw_geometries([pcd])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.97852   1.19141  -2.0918  ]\n",
      " [-1.96973   1.19141  -2.0918  ]\n",
      " [-1.97461   1.20117  -2.10742 ]\n",
      " ...\n",
      " [ 0.442383 -0.252197 -0.442627]\n",
      " [ 0.44458  -0.252197 -0.442627]\n",
      " [ 0.446533 -0.252197 -0.442627]]\n",
      "----------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([False, False, False, ...,  True,  True,  True])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_xyz = np.asarray(pcd.points)\n",
    "print(n_xyz)\n",
    "print(\"----------------------------\")\n",
    "n_xyz[:, 0] > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Crop Img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#crop data\n",
    "def crop(pcd, range_x, range_y, range_z):\n",
    "  n_xyz = np.asarray(pcd.points)\n",
    "  mask_x = (n_xyz[:, 0] > range_x[0]) & (n_xyz[:, 0] < range_x[1])\n",
    "  \n",
    "  # print(mask_x)\n",
    "  mask_y = (n_xyz[:, 1] > range_y[0]) & (n_xyz[:, 1] < range_y[1])\n",
    "  mask_z = (n_xyz[:, 2] > range_z[0]) & (n_xyz[:, 2] < range_z[1])\n",
    "  mask = mask_x & mask_y & mask_z\n",
    "  # print(mask)\n",
    "  cropPCD = o3d.geometry.PointCloud()\n",
    "  cropPCD.points = o3d.utility.Vector3dVector(n_xyz[mask])\n",
    "  return cropPCD\n",
    "\n",
    "newPCD = crop(pcd, [-0.5,0.5], [-0.5,0.5], [-1.25,0])\n",
    "# o3d.visualization.draw_geometries([newPCD])\n",
    "# crop2(pcd, min_x, min_y, min_z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. DownSampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#down sample\n",
    "downPCD = newPCD.voxel_down_sample(voxel_size = 0.01  )\n",
    "# downPCD = voxel_down_sample(newPCD, voxel_size = 0.01) => error\n",
    "\n",
    "#rotate img\n",
    "# R = downPCD.get_rotation_matrix_from_xyz((0.7 * np.pi, 0, 0.6 * np.pi))\n",
    "# downPCD = downPCD.rotate(R, center=(0,0,0))\n",
    "# o3d.visualization.draw_geometries([downPCD])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Plane segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plane equation: -0.08x + 0.84y + 0.54z + 0.48 = 0\n",
      "Number of points in the plane: 6091\n",
      "Number of points in the plane: 1997\n",
      "Processing with the 1 loop\n",
      "Number of points in the plane: 1143\n",
      "Number of points in the other: 854\n"
     ]
    }
   ],
   "source": [
    "# Plane segmentation\n",
    "def plane(newPCD):\n",
    "    plane_model, inliers = newPCD.segment_plane(distance_threshold=0.01,\n",
    "                                         ransac_n=3,\n",
    "                                         num_iterations=1000)\n",
    "    [a, b, c, d] = plane_model\n",
    "    print(f\"Plane equation: {a:.2f}x + {b:.2f}y + {c:.2f}z + {d:.2f} = 0\")\n",
    "\n",
    "    plane = newPCD.select_by_index(inliers)\n",
    "    # Count points in plane\n",
    "    points_plane = np.asarray(plane.points)\n",
    "    print(f\"Number of points in the plane: {points_plane.shape[0]}\")\n",
    "\n",
    "    # inlier_cloud.paint_uniform_color([1.0, 0, 0])\n",
    "    other = newPCD.select_by_index(inliers, invert=True)\n",
    "    points_others = np.asarray(other.points)\n",
    "    print(f\"Number of points in the plane: {points_others.shape[0]}\")\n",
    "\n",
    "    # Processing with loop\n",
    "    i = 1\n",
    "    while points_others.shape[0] > 0:\n",
    "        print(\"Processing with the {} loop\".format(i))\n",
    "        i += 1\n",
    "        # Segment plane\n",
    "        plane_model, inliers = other.segment_plane(distance_threshold=0.01,\n",
    "                                                    ransac_n=3,\n",
    "                                                    num_iterations=1000)\n",
    "        # Extract inliers and outliers\n",
    "        plane = other.select_by_index(inliers)\n",
    "        other = other.select_by_index(inliers, invert=True)\n",
    "        # Count points in plane\n",
    "        points_plane = np.asarray(plane.points)\n",
    "        print(f\"Number of points in the plane: {points_plane.shape[0]}\")\n",
    "        # Count points in other\n",
    "        points_others = np.asarray(other.points)\n",
    "        print(f\"Number of points in the other: {points_others.shape[0]}\")\n",
    "        # Visualize\n",
    "        o3d.visualization.draw_geometries([plane])\n",
    "        # Break if no points left\n",
    "        if points_others.shape[0] == 0:\n",
    "            break\n",
    "        # Update\n",
    "        plane = other\n",
    "        # other = other.select_by_index(inliers, invert=True)\n",
    "        return plane\n",
    "\n",
    "\n",
    "    # return plane, points_plane, other, points_others\n",
    "plane = plane(downPCD)\n",
    "\n",
    "# place_plane, count_points_1, other, points_others = plane(downPCD)\n",
    "# o3d.visualization.draw_geometries([other])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Count the number of points in each plane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "## License: Apache 2.0. See LICENSE file in root directory.\n",
    "## Copyright(c) 2015-2017 Intel Corporation. All Rights Reserved.\n",
    "\n",
    "###############################################\n",
    "##      Open CV and Numpy integration        ##\n",
    "###############################################\n",
    "\n",
    "import pyrealsense2 as rs\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "from config import *\n",
    "\n",
    "# Create Trackbar for Threshold\n",
    "# cv2.namedWindow('Depth Image')\n",
    "cv2.namedWindow('RealSense', cv2.WINDOW_AUTOSIZE)\n",
    "cv2.createTrackbar('FPS', 'RealSense', 0, 50, lambda x: x+1)\n",
    "\n",
    "# Configure depth and color streams\n",
    "pipeline = rs.pipeline()\n",
    "config = rs.config()\n",
    "\n",
    "# Get device product line for setting a supporting resolution\n",
    "pipeline_wrapper = rs.pipeline_wrapper(pipeline)\n",
    "pipeline_profile = config.resolve(pipeline_wrapper)\n",
    "device = pipeline_profile.get_device()\n",
    "device_product_line = str(device.get_info(rs.camera_info.product_line))\n",
    "\n",
    "found_rgb = False\n",
    "for s in device.sensors:\n",
    "    if s.get_info(rs.camera_info.name) == 'RGB Camera':\n",
    "        found_rgb = True\n",
    "        break\n",
    "if not found_rgb:\n",
    "    print(\"The demo requires Depth camera with Color sensor\")\n",
    "    exit(0)\n",
    "\n",
    "fps = cv2.getTrackbarPos('FPS', 'RealSense')\n",
    "print(fps)\n",
    "config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, fps)\n",
    "\n",
    "if device_product_line == 'L500':\n",
    "    config.enable_stream(rs.stream.color, 960, 540, rs.format.bgr8, fps)\n",
    "else:\n",
    "    config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, fps)\n",
    "\n",
    "# Start streaming\n",
    "pipeline.start(config)\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        # print(pipeline)\n",
    "        # Wait for a coherent pair of frames: depth and color\n",
    "        frames = pipeline.wait_for_frames()\n",
    "        depth_frame = frames.get_depth_frame()\n",
    "        color_frame = frames.get_color_frame()\n",
    "        if not depth_frame or not color_frame:\n",
    "            continue\n",
    "        \n",
    "        # Convert images to numpy arrays\n",
    "        depth_image = np.asanyarray(depth_frame.get_data())\n",
    "        color_image = np.asanyarray(color_frame.get_data())\n",
    "\n",
    "        # Apply colormap on depth image (image must be converted to 8-bit per pixel first)\n",
    "        depth_colormap = cv2.applyColorMap(cv2.convertScaleAbs(depth_image, alpha=0.03), cv2.COLORMAP_JET)\n",
    "\n",
    "        depth_colormap_dim = depth_colormap.shape\n",
    "        color_colormap_dim = color_image.shape\n",
    "\n",
    "        # If depth and color resolutions are different, resize color image to match depth image for display\n",
    "        if depth_colormap_dim != color_colormap_dim:\n",
    "            resized_color_image = cv2.resize(color_image, dsize=(depth_colormap_dim[1], depth_colormap_dim[0]), interpolation=cv2.INTER_AREA)\n",
    "            images = np.hstack((resized_color_image, depth_colormap))\n",
    "        else:\n",
    "            images = np.hstack((color_image, depth_colormap))\n",
    "        \n",
    "        # Flip camera image\n",
    "        images = cv2.flip(images, 1)\n",
    "\n",
    "        # Save images\n",
    "        import os\n",
    "        # Create directory if not exist\n",
    "        if not os.path.exists('images'):\n",
    "            os.mkdir('images')\n",
    "        \n",
    "        if count // 2 == 0:\n",
    "            if len(os.listdir(\"./images\"))!=10:\n",
    "                cv2.imwrite(\"./images/image_\" + str(count) + \".png\", images)    \n",
    "        count += 1\n",
    "\n",
    "        # Show images\n",
    "        cv2.namedWindow('RealSense', cv2.WINDOW_AUTOSIZE)\n",
    "        cv2.imshow('RealSense', images)\n",
    "        key = cv2.waitKey(1)\n",
    "        # Press esc or 'q' to close the image window\n",
    "        if key & 0xFF == ord('q') or key == 27:\n",
    "            cv2.destroyAllWindows()\n",
    "            break\n",
    "        \n",
    "finally:\n",
    "\n",
    "    # Stop streaming\n",
    "    pipeline.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
